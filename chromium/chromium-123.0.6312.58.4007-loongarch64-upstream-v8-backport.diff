diff '--color=auto' -p -X ../chromium-loongarch64/chromium/exclude -N -u -r a/v8/src/builtins/loong64/builtins-loong64.cc b/v8/src/builtins/loong64/builtins-loong64.cc
--- a/v8/src/builtins/loong64/builtins-loong64.cc	2000-01-01 00:00:00.000000000 +0800
+++ b/v8/src/builtins/loong64/builtins-loong64.cc	2000-01-01 00:00:00.000000000 +0800
@@ -1334,7 +1334,7 @@ void Builtins::Generate_InterpreterEntry
     __ Move(a2, kInterpreterBytecodeArrayRegister);
     static_assert(kJavaScriptCallCodeStartRegister == a2, "ABI mismatch");
     __ ReplaceClosureCodeWithOptimizedCode(a2, closure);
-    __ JumpCodeObject(a2);
+    __ JumpCodeObject(a2, kJSEntrypointTag);
 
     __ bind(&install_baseline_code);
     __ GenerateTailCallToReturnedCode(Runtime::kInstallBaselineCode);
@@ -1714,7 +1714,7 @@ static void Generate_InterpreterEnterByt
 
   __ LoadTaggedField(
       t0, FieldMemOperand(t0, InterpreterData::kInterpreterTrampolineOffset));
-  __ LoadCodeInstructionStart(t0, t0);
+  __ LoadCodeInstructionStart(t0, t0, kJSEntrypointTag);
   __ Branch(&trampoline_loaded);
 
   __ bind(&builtin_trampoline);
@@ -1983,7 +1983,7 @@ void OnStackReplacement(MacroAssembler*
                                       DeoptimizationData::kOsrPcOffsetIndex) -
                                       kHeapObjectTag));
 
-  __ LoadCodeInstructionStart(maybe_target_code, maybe_target_code);
+  __ LoadCodeInstructionStart(maybe_target_code, maybe_target_code, kJSEntrypointTag);
 
   // Compute the target address = code_entry + osr_offset
   // <entry_addr> = <code_entry> + <osr_offset>
@@ -3951,7 +3951,7 @@ void Generate_BaselineOrInterpreterEntry
     __ PrepareCallCFunction(3, 0, a4);
     __ CallCFunction(get_baseline_pc, 3, 0);
   }
-  __ LoadCodeInstructionStart(code_obj, code_obj);
+  __ LoadCodeInstructionStart(code_obj, code_obj, kJSEntrypointTag);
   __ Add_d(code_obj, code_obj, kReturnRegister0);
   __ Pop(kInterpreterAccumulatorRegister);
 
diff '--color=auto' -p -X ../chromium-loongarch64/chromium/exclude -N -u -r a/v8/src/codegen/loong64/macro-assembler-loong64.cc b/v8/src/codegen/loong64/macro-assembler-loong64.cc
--- a/v8/src/codegen/loong64/macro-assembler-loong64.cc	2000-01-01 00:00:00.000000000 +0800
+++ b/v8/src/codegen/loong64/macro-assembler-loong64.cc	2000-01-01 00:00:00.000000000 +0800
@@ -353,15 +353,20 @@ void MacroAssembler::ResolveCodePointerH
 }
 
 void MacroAssembler::LoadCodeEntrypointViaCodePointer(
-    Register destination, MemOperand field_operand) {
+    Register destination, MemOperand field_operand, CodeEntrypointTag tag) {
+  DCHECK_NE(tag, kInvalidEntrypointTag);
   ASM_CODE_COMMENT(this);
   UseScratchRegisterScope temps(this);
-  Register table = temps.Acquire();
-  li(table, ExternalReference::code_pointer_table_address());
+  Register scratch = temps.Acquire();
+  li(scratch, ExternalReference::code_pointer_table_address());
   Ld_wu(destination, field_operand);
   srli_d(destination, destination, kCodePointerHandleShift);
   slli_d(destination, destination, kCodePointerTableEntrySizeLog2);
-  Ld_d(destination, MemOperand(table, destination));
+  Ld_d(destination, MemOperand(scratch, destination));
+  if (tag != 0) {
+    li(scratch, Operand(tag));
+    xor_(destination, destination, scratch);
+  }
 }
 #endif  // V8_ENABLE_SANDBOX
 
@@ -4596,28 +4601,29 @@ void MacroAssembler::CallForDeoptimizati
 }
 
 void MacroAssembler::LoadCodeInstructionStart(Register destination,
-                                              Register code_object) {
+                                              Register code_object,
+                                              CodeEntrypointTag tag) {
   ASM_CODE_COMMENT(this);
 #ifdef V8_ENABLE_SANDBOX
   LoadCodeEntrypointViaCodePointer(
       destination,
-      FieldMemOperand(code_object, Code::kSelfIndirectPointerOffset));
+      FieldMemOperand(code_object, Code::kSelfIndirectPointerOffset), tag);
 #else
   Ld_d(destination,
        FieldMemOperand(code_object, Code::kInstructionStartOffset));
 #endif
 }
 
-void MacroAssembler::CallCodeObject(Register code_object) {
+void MacroAssembler::CallCodeObject(Register code_object, CodeEntrypointTag tag) {
   ASM_CODE_COMMENT(this);
-  LoadCodeInstructionStart(code_object, code_object);
+  LoadCodeInstructionStart(code_object, code_object, tag);
   Call(code_object);
 }
 
-void MacroAssembler::JumpCodeObject(Register code_object, JumpMode jump_mode) {
+void MacroAssembler::JumpCodeObject(Register code_object, CodeEntrypointTag tag, JumpMode jump_mode) {
   ASM_CODE_COMMENT(this);
   DCHECK_EQ(JumpMode::kJump, jump_mode);
-  LoadCodeInstructionStart(code_object, code_object);
+  LoadCodeInstructionStart(code_object, code_object, tag);
   Jump(code_object);
 }
 
@@ -4628,12 +4634,12 @@ void MacroAssembler::CallJSFunction(Regi
   // from the code pointer table instead of going through the Code object. In
   // this way, we avoid one memory load on this code path.
   LoadCodeEntrypointViaCodePointer(
-      code, FieldMemOperand(function_object, JSFunction::kCodeOffset));
+      code, FieldMemOperand(function_object, JSFunction::kCodeOffset), kJSEntrypointTag);
   Call(code);
 #else
   LoadTaggedField(code,
                   FieldMemOperand(function_object, JSFunction::kCodeOffset));
-  CallCodeObject(code);
+  CallCodeObject(code, kJSEntrypointTag);
 #endif
 }
 
@@ -4645,13 +4651,13 @@ void MacroAssembler::JumpJSFunction(Regi
   // from the code pointer table instead of going through the Code object. In
   // this way, we avoid one memory load on this code path.
   LoadCodeEntrypointViaCodePointer(
-      code, FieldMemOperand(function_object, JSFunction::kCodeOffset));
+      code, FieldMemOperand(function_object, JSFunction::kCodeOffset), kJSEntrypointTag);
   DCHECK_EQ(jump_mode, JumpMode::kJump);
   Jump(code);
 #else
   LoadTaggedField(code,
                   FieldMemOperand(function_object, JSFunction::kCodeOffset));
-  JumpCodeObject(code, jump_mode);
+  JumpCodeObject(code, kJSEntrypointTag, jump_mode);
 #endif
 }
 
@@ -4691,7 +4697,7 @@ void TailCallOptimizedCodeSlot(MacroAsse
   __ ReplaceClosureCodeWithOptimizedCode(optimized_code_entry, closure);
 
   static_assert(kJavaScriptCallCodeStartRegister == a2, "ABI mismatch");
-  __ LoadCodeInstructionStart(a2, optimized_code_entry);
+  __ LoadCodeInstructionStart(a2, optimized_code_entry, kJSEntrypointTag);
   __ Jump(a2);
 
   // Optimized code slot contains deoptimized code or code is cleared and
@@ -4748,7 +4754,7 @@ void MacroAssembler::GenerateTailCallToR
          kJavaScriptCallArgCountRegister, kJavaScriptCallTargetRegister);
 
     CallRuntime(function_id, 1);
-    LoadCodeInstructionStart(a2, a0);
+    LoadCodeInstructionStart(a2, a0, kJSEntrypointTag);
     // Restore target function, new target and actual argument count.
     Pop(kJavaScriptCallTargetRegister, kJavaScriptCallNewTargetRegister,
         kJavaScriptCallArgCountRegister);
diff '--color=auto' -p -X ../chromium-loongarch64/chromium/exclude -N -u -r a/v8/src/codegen/loong64/macro-assembler-loong64.h b/v8/src/codegen/loong64/macro-assembler-loong64.h
--- a/v8/src/codegen/loong64/macro-assembler-loong64.h	2000-01-01 00:00:00.000000000 +0800
+++ b/v8/src/codegen/loong64/macro-assembler-loong64.h	2000-01-01 00:00:00.000000000 +0800
@@ -222,9 +222,9 @@ class V8_EXPORT_PRIVATE MacroAssembler :
                        Operand range);
 
   // Load the code entry point from the Code object.
-  void LoadCodeInstructionStart(Register destination, Register code_object);
-  void CallCodeObject(Register code_object);
-  void JumpCodeObject(Register code_object,
+  void LoadCodeInstructionStart(Register destination, Register code_object, CodeEntrypointTag tag);
+  void CallCodeObject(Register code_object, CodeEntrypointTag tag);
+  void JumpCodeObject(Register code_object, CodeEntrypointTag tag,
                       JumpMode jump_mode = JumpMode::kJump);
 
   // Convenience functions to call/jmp to the code of a JSFunction object.
@@ -893,7 +893,8 @@ class V8_EXPORT_PRIVATE MacroAssembler :
   // Only available when the sandbox is enabled as it requires the code pointer
   // table.
   void LoadCodeEntrypointViaCodePointer(Register destination,
-                                        MemOperand field_operand);
+                                        MemOperand field_operand,
+                                        CodeEntrypointTag tag);
 #endif
 
   // Load a protected pointer field.
diff '--color=auto' -p -X ../chromium-loongarch64/chromium/exclude -N -u -r a/v8/src/compiler/backend/loong64/code-generator-loong64.cc b/v8/src/compiler/backend/loong64/code-generator-loong64.cc
--- a/v8/src/compiler/backend/loong64/code-generator-loong64.cc	2000-01-01 00:00:00.000000000 +0800
+++ b/v8/src/compiler/backend/loong64/code-generator-loong64.cc	2000-01-01 00:00:00.000000000 +0800
@@ -645,10 +645,12 @@ CodeGenerator::CodeGenResult CodeGenerat
         __ Call(i.InputCode(0), RelocInfo::CODE_TARGET);
       } else {
         Register reg = i.InputRegister(0);
+        CodeEntrypointTag tag =
+            i.InputCodeEntrypointTag(instr->CodeEnrypointTagInputIndex());
         DCHECK_IMPLIES(
             instr->HasCallDescriptorFlag(CallDescriptor::kFixedTargetRegister),
             reg == kJavaScriptCallCodeStartRegister);
-        __ CallCodeObject(reg);
+        __ CallCodeObject(reg, tag);
       }
       RecordCallPosition(instr);
       frame_access_state()->ClearSPDelta();
@@ -697,10 +699,12 @@ CodeGenerator::CodeGenResult CodeGenerat
         __ Jump(i.InputCode(0), RelocInfo::CODE_TARGET);
       } else {
         Register reg = i.InputRegister(0);
+        CodeEntrypointTag tag =
+            i.InputCodeEntrypointTag(instr->CodeEnrypointTagInputIndex());
         DCHECK_IMPLIES(
             instr->HasCallDescriptorFlag(CallDescriptor::kFixedTargetRegister),
             reg == kJavaScriptCallCodeStartRegister);
-        __ JumpCodeObject(reg);
+        __ JumpCodeObject(reg, tag);
       }
       frame_access_state()->ClearSPDelta();
       frame_access_state()->SetFrameAccessToDefault();
diff '--color=auto' -p -X ../chromium-loongarch64/chromium/exclude -N -u -r a/v8/src/wasm/baseline/loong64/liftoff-assembler-loong64-inl.h b/v8/src/wasm/baseline/loong64/liftoff-assembler-loong64-inl.h
--- a/v8/src/wasm/baseline/loong64/liftoff-assembler-loong64-inl.h	2000-01-01 00:00:00.000000000 +0800
+++ b/v8/src/wasm/baseline/loong64/liftoff-assembler-loong64-inl.h	2000-01-01 00:00:00.000000000 +0800
@@ -472,6 +472,11 @@ void LiftoffAssembler::LoadTaggedPointer
   }
 }
 
+void LiftoffAssembler::LoadProtectedPointer(Register dst, Register src_addr,
+                                            int32_t offset_imm) {
+  LoadProtectedPointerField(dst, MemOperand{src_addr, offset_imm});
+}
+
 void LiftoffAssembler::LoadFullPointer(Register dst, Register src_addr,
                                        int32_t offset_imm) {
   MemOperand src_op = liftoff::GetMemOp(this, src_addr, no_reg, offset_imm);
@@ -483,7 +488,7 @@ void LiftoffAssembler::LoadCodeEntrypoin
                                                         Register src_addr,
                                                         int32_t offset_imm) {
   MemOperand src_op = liftoff::GetMemOp(this, src_addr, no_reg, offset_imm);
-  MacroAssembler::LoadCodeEntrypointViaCodePointer(dst, src_op);
+  MacroAssembler::LoadCodeEntrypointViaCodePointer(dst, src_op, kWasmEntrypointTag);
 }
 #endif
 
@@ -1287,6 +1292,18 @@ void LiftoffAssembler::emit_i64_mul(Lift
   MacroAssembler::Mul_d(dst.gp(), lhs.gp(), rhs.gp());
 }
 
+void LiftoffAssembler::emit_i64_muli(LiftoffRegister dst, LiftoffRegister lhs,
+                                     int32_t imm) {
+  if (base::bits::IsPowerOfTwo(imm)) {
+    emit_i64_shli(dst, lhs, base::bits::WhichPowerOfTwo(imm));
+    return;
+  }
+  UseScratchRegisterScope temps(this);
+  Register scratch = temps.Acquire();
+  MacroAssembler::li(scratch, Operand(imm));
+  MacroAssembler::Mul_d(dst.gp(), lhs.gp(), scratch);
+}
+
 bool LiftoffAssembler::emit_i64_divs(LiftoffRegister dst, LiftoffRegister lhs,
                                      LiftoffRegister rhs,
                                      Label* trap_div_by_zero,
